---
title: "Untitled"
output: html_document
---

```{r}
parsed <- readLines("C:\\Users\\Windows\\Desktop\\d.txt", encoding='UTF-8')
#parsed <- read.csv('C:\\Users\\Windows\\Downloads\\word2vec.txt', fileEncoding='utf-8', sep=" ", header=F, skip=1)
length(x = parsed)

parsed[1:3]
```




```{r}
# 필요한 패키지를 불러옵니다.
library(tm)
library(dplyr)
# 말뭉치를 생성합니다. 
corpus <- parsed %>% VectorSource() %>% VCorpus()
print(corpus)

tdm <- TermDocumentMatrix(corpus)
```

```{r}
#str(object = corpus[[1]])
```

```{r}
# 필요한 패키지를 불러옵니다. 
library(RWeka)
# 인접한 2개의 단어를 결합한 bigram을 생성합니다. 
# min과 max에 할당할 숫자를 바꾸면 원하는 N-gram을 만들 수 있습니다. 
bigram <- function(x) {
  NGramTokenizer(x = x, control = Weka_control(min = 2, max = 4))
}

#corpus[!is.na(corpus)] <- "NA"

corpus <- tm_map(corpus, content_transformer(tolower))

# 단어문서행렬(Term-Document matrix)을 생성합니다. 
bigramList <- corpus %>%
  TermDocumentMatrix(control = list(tokenize = bigram)) %>% 
  apply(MARGIN = 1, FUN = sum) %>% 
  sort(decreasing = TRUE)

# bigram의 길이를 확인합니다. 
length(bigramList)
## [1] 8396
# 문서 개수의 1% 이상 발생하는 bigram만 남깁니다. 
# 빈도수가 작은 것은 굳이 관심을 가지지 않아도 됩니다. 
#bigramList <- bigramList[bigramList >= (nrow(x = texts) * 0.01)]
length(x = bigramList)
## [1] 451
# bigram의 컬럼명(글자)만 따로 추출하여 bigramNames에 할당합니다. 
bigramNames <- names(bigramList)

# bigramNames을 육안으로 확인하기 위해 최대 100개까지 출력합니다. 
top <- if (length(x = bigramList) >= 300) bigramList[1:150] else bigramNames
print(top)


```


```{r}
write.xlsx(as.data.frame(bigramList),"bigramList.xlsx",row.names = FALSE)
```


